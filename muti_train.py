import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from sklearn.manifold import TSNE
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np
import os
import random
from PIL import Image
from sklearn.metrics import f1_score, recall_score, precision_score
from tqdm import tqdm



def seed_everything(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# æ•°æ®å¢å¼ºå’Œé¢„å¤„ç†
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=6),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])


class SpectrogramDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.image_files = [f for f in os.listdir(root_dir) if f.endswith('.jpg')]
        self.labels = [int(f.split('-')[1].split('.')[0]) for f in self.image_files]

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = os.path.join(self.root_dir, self.image_files[idx])
        image = Image.open(img_path).convert('RGB')
        label = self.labels[idx]
        return self.transform(image) if self.transform else image, label


class CNN(nn.Module):
    def __init__(self, num_classes=6, base_channels=32, dropout_rate=0.3,
                 extra_conv_layers=1, use_attention=True, kernel_size=3):
        super().__init__()
        self.features = self._make_layers(base_channels, extra_conv_layers, kernel_size)

        if use_attention:
            self.attention = nn.Sequential(
                nn.Conv2d(base_channels * (2 ** extra_conv_layers),
                          base_channels * (2 ** extra_conv_layers) // 8, 1),
                nn.ReLU(),
                nn.Conv2d(base_channels * (2 ** extra_conv_layers) // 8,
                          base_channels * (2 ** extra_conv_layers), 1),
                nn.Sigmoid()
            )
        else:
            self.attention = None

        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(base_channels * (2 ** extra_conv_layers), 512),
            nn.LeakyReLU(0.1),
            nn.Dropout(dropout_rate),
            nn.Linear(512, num_classes)
        )

    def _make_layers(self, base_channels, num_layers, kernel_size):
        layers = []
        current_channels = base_channels
        layers += [
            nn.Conv2d(3, current_channels, kernel_size, padding=1),
            nn.BatchNorm2d(current_channels),
            nn.LeakyReLU(0.1),
            nn.MaxPool2d(2, 2)
        ]

        for _ in range(num_layers):
            layers += [
                nn.Conv2d(current_channels, current_channels * 2, kernel_size, padding=1),
                nn.BatchNorm2d(current_channels * 2),
                nn.LeakyReLU(0.1),
                nn.MaxPool2d(2, 2)
            ]
            current_channels *= 2
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.features(x)
        if self.attention is not None:
            x = x * self.attention(x)
        return self.classifier(x)


def run_experiment(seed, num_epochs=60, visualize=False):
    seed_everything(seed)

    # æ•°æ®åŠ è½½
    train_dataset = SpectrogramDataset(r'D:\aa_my_learning\my_learining\é¡¹ç›®1\çŸ­æ—¶å‚…é‡Œå¶æ—¶é¢‘\train_img',
                                       train_transform)
    val_dataset = SpectrogramDataset(r'D:\aa_my_learning\my_learining\é¡¹ç›®1\çŸ­æ—¶å‚…é‡Œå¶æ—¶é¢‘\valid_img', test_transform)
    test_dataset = SpectrogramDataset(r'D:\aa_my_learning\my_learining\é¡¹ç›®1\çŸ­æ—¶å‚…é‡Œå¶æ—¶é¢‘\test_img', test_transform)

    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

    # æ¨¡å‹åˆå§‹åŒ–
    model = CNN(num_classes=6, base_channels=50, extra_conv_layers=0,
                use_attention=False, dropout_rate=0.19906,kernel_size=3).to(device)
    optimizer = optim.AdamW(model.parameters(), lr=0.000205, weight_decay=4.4696e-05)

    criterion = nn.CrossEntropyLoss()
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)

    best_val_acc = 0.0
    best_model_state = None
    patience = 20
    no_improve = 0

    # è®­ç»ƒå¾ªç¯
    for epoch in range(num_epochs):
        model.train()
        train_loss, train_correct, train_total = 0.0, 0, 0

        train_bar = tqdm(train_loader, desc=f'Train Epoch {epoch + 1}/{num_epochs}',
                         bar_format='{l_bar}{bar:20}{r_bar}{bar:-20b}')

        for inputs, labels in train_bar:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            batch_size = inputs.size(0)
            train_loss += loss.item() * batch_size
            _, predicted = torch.max(outputs.data, 1)
            train_correct += (predicted == labels).sum().item()
            train_total += batch_size


            train_bar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'acc': f'{(predicted == labels).sum().item() / batch_size:.3f}',
                'lr': f'{optimizer.param_groups[0]["lr"]:.2e}'
            })

        # è®¡ç®—è®­ç»ƒæŒ‡æ ‡
        train_loss = train_loss / train_total
        train_acc = train_correct / train_total

        # éªŒè¯æ­¥éª¤
        model.eval()
        val_loss, val_correct, val_total = 0.0, 0, 0
        val_bar = tqdm(val_loader, desc='Validating',
                       bar_format='{l_bar}{bar:20}{r_bar}{bar:-20b}', leave=False)

        with torch.no_grad():
            for inputs, labels in val_bar:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)

                batch_size = inputs.size(0)
                val_loss += loss.item() * batch_size
                _, predicted = torch.max(outputs.data, 1)
                val_correct += (predicted == labels).sum().item()
                val_total += batch_size

                val_bar.set_postfix({
                    'val_loss': f'{loss.item():.4f}',
                    'val_acc': f'{(predicted == labels).sum().item() / batch_size:.3f}'
                })

        # è®¡ç®—éªŒè¯æŒ‡æ ‡
        val_loss = val_loss / val_total
        val_acc = val_correct / val_total

        # æ‰“å°epochæ€»ç»“
        print(f"\nEpoch {epoch + 1:02d}/{num_epochs} Summary:")
        print(f"Train Loss: {train_loss:.4f}  Acc: {train_acc:.4f} | "
              f"Val Loss: {val_loss:.4f}  Acc: {val_acc:.4f} | "
              f"LR: {optimizer.param_groups[0]['lr']:.2e}")

        # æ—©åœæœºåˆ¶
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model_state = model.state_dict()
            no_improve = 0
            print(f"ğŸ”¥ New best validation accuracy: {val_acc:.4f}")
        else:
            no_improve += 1
            print(f"â³ No improvement for {no_improve}/{patience} epochs")
            if no_improve >= patience:
                print(f"ğŸ›‘ Early stopping at epoch {epoch + 1}")
                break

        scheduler.step()

    # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•
    model.load_state_dict(best_model_state)
    test_acc, test_f1, test_recall, test_precision = evaluate_model(model, test_loader, seed, visualize)

    return test_acc, test_f1, test_recall, test_precision


def evaluate_model(model, test_loader, seed, visualize):
    model.eval()
    all_labels = []
    all_preds = []
    all_features = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs = inputs.to(device)
            features = model.features(inputs)
            features = torch.flatten(nn.AdaptiveAvgPool2d(1)(features), start_dim=1)
            outputs = model(inputs)

            all_features.append(features.cpu().numpy())
            all_labels.extend(labels.numpy())
            all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())

    # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
    accuracy = np.mean(np.array(all_labels) == np.array(all_preds))
    f1 = f1_score(all_labels, all_preds, average='macro')
    recall = recall_score(all_labels, all_preds, average='macro')
    precision = precision_score(all_labels, all_preds, average='macro')

    if visualize:
        # t-SNEå¯è§†åŒ–ï¼ˆæ·»åŠ å›¾ä¾‹ç‰ˆæœ¬ï¼‰
        tsne = TSNE(n_components=2, perplexity=30, random_state=seed)
        features_2d = tsne.fit_transform(np.concatenate(all_features))

        plt.figure(figsize=(10, 8))
        unique_labels = np.unique(all_labels)
        cmap = plt.get_cmap('tab10', len(unique_labels))  # ä½¿ç”¨tab10é¢œè‰²æ˜ å°„

        # ä¸ºæ¯ä¸ªç±»åˆ«å•ç‹¬ç»˜åˆ¶ç‚¹å¹¶æ·»åŠ æ ‡ç­¾
        for label in unique_labels:
            mask = np.array(all_labels) == label
            plt.scatter(features_2d[mask, 0],
                        features_2d[mask, 1],
                        color=cmap(label),  # æ ¹æ®æ ‡ç­¾å€¼é€‰æ‹©é¢œè‰²
                        label=f'Class {label}',
                        alpha=0.6,
                        edgecolors='w')

        # æ·»åŠ å›¾ä¾‹å¹¶è°ƒæ•´å¸ƒå±€
        plt.legend(title='Classes',
                   bbox_to_anchor=(1.05, 1),
                   loc='upper left',
                   borderaxespad=0.)
        plt.title(f't-SNE Visualization (Seed {seed})')
        plt.tight_layout()  # é˜²æ­¢å›¾ä¾‹è¢«æˆªæ–­
        plt.savefig(f'tsne_seed_{seed}.png', bbox_inches='tight')  # ä¿å­˜å®Œæ•´å›¾åƒ
        plt.close()

        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(all_labels, all_preds)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        disp.plot(cmap='Blues')
        plt.title(f'Confusion Matrix (Seed {seed})')
        plt.savefig(f'cm_seed_{seed}.png')
        plt.close()

    return accuracy, f1, recall, precision


if __name__ == "__main__":
    num_runs = 1
    seeds = [42 + i for i in range(num_runs)]

    # åˆå§‹åŒ–æ‰€æœ‰æŒ‡æ ‡çš„å­˜å‚¨åˆ—è¡¨
    accuracies = []
    f1_scores = []
    recalls = []
    precisions = []

    # åˆ›å»ºå¹¶æ‰“å¼€ç»“æœæ–‡ä»¶
    with open('experiment_results.txt', 'w') as f:
        f.write("========== å®éªŒæŠ¥å‘Š ==========\n\n")
        f.write(f"è¿è¡Œæ¬¡æ•°: {num_runs}\n")
        f.write(f"ä½¿ç”¨çš„éšæœºç§å­: {seeds}\n\n")

        for i, seed in enumerate(seeds):
            print(f"\n=== Running with seed {seed} ({i + 1}/{num_runs}) ===")
            f.write(f"\n=== ç¬¬ {i + 1}/{num_runs} æ¬¡è¿è¡Œï¼ˆç§å­ {seed}ï¼‰ ===\n")

            # è·å–æ‰€æœ‰æŒ‡æ ‡
            acc, f1, recall, precision = run_experiment(seed,num_epochs=2, visualize=(i == num_runs - 1))

            # å­˜å‚¨ç»“æœ
            accuracies.append(acc)
            f1_scores.append(f1)
            recalls.append(recall)
            precisions.append(precision)

            # æ‰“å°å¹¶ä¿å­˜è¯¦ç»†ç»“æœ
            print(f"Seed {seed} Results:")
            print(f"Test Accuracy: {acc:.4f}")
            print(f"F1 Score: {f1:.4f}")
            print(f"Recall: {recall:.4f}")
            print(f"Precision: {precision:.4f}")

            f.write(f"æµ‹è¯•å‡†ç¡®ç‡: {acc:.4f}\n")
            f.write(f"F1åˆ†æ•°: {f1:.4f}\n")
            f.write(f"å¬å›ç‡: {recall:.4f}\n")
            f.write(f"ç²¾ç¡®ç‡: {precision:.4f}\n")

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        final_report = [
            "\n========== æœ€ç»ˆç»Ÿè®¡ç»“æœ ==========",
            f"å¹³å‡æµ‹è¯•å‡†ç¡®ç‡: {np.mean(accuracies):.4f} Â± {np.std(accuracies):.4f}",
            f"å¹³å‡F1åˆ†æ•°: {np.mean(f1_scores):.4f} Â± {np.std(f1_scores):.4f}",
            f"å¹³å‡å¬å›ç‡: {np.mean(recalls):.4f} Â± {np.std(recalls):.4f}",
            f"å¹³å‡ç²¾ç¡®ç‡: {np.mean(precisions):.4f} Â± {np.std(precisions):.4f}",
            "\nè¯¦ç»†æ•°æ®:",
            "å‡†ç¡®ç‡åˆ—è¡¨: " + ", ".join([f"{x:.4f}" for x in accuracies]),
            "F1åˆ†æ•°åˆ—è¡¨: " + ", ".join([f"{x:.4f}" for x in f1_scores]),
            "å¬å›ç‡åˆ—è¡¨: " + ", ".join([f"{x:.4f}" for x in recalls]),
            "ç²¾ç¡®ç‡åˆ—è¡¨: " + ", ".join([f"{x:.4f}" for x in precisions])
        ]

        # è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
        print("\n".join(final_report))
        f.write("\n".join(final_report))

    print("\nå®éªŒç»“æœå·²ä¿å­˜åˆ° experiment_results.txt")